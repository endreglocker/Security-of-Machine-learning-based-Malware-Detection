# Security of Machine learning based Malware Detection
## Coordinator: √Åcs Gergely PhD
## Glocker Endre
### 2024 spring semester

Adversarial examples are maliciously modified program code where the modification is hard to detect yet the prediction of the model on this slightly modified code is very different compared to the unmodified code. For example, the malware developer modifies a few bytes in the malware binary which causes the malware detector to misclassify the malware as benign. A potential task can be to develop solutions to detect adversarial examples, develop robust training algorithms for malware detection, or design backdoor attacks. 
