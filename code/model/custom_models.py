import torch.nn as nn

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Sequential(         
            nn.Conv1d(
                in_channels=1, # original 1 
                out_channels=16, # number of dectection channels / filters     original 16
                kernel_size=10, # width of the scanning window: 10 units          original 10
                stride=1, # number of units by which the kernel is shifted when the convolution is performed #original 1              
                padding=0, # original 0                  
            ),                              
            nn.ReLU(),                      
            nn.MaxPool1d(kernel_size=2),    
        )
        self.out = nn.Linear(524208, 1)
        # 1475344 for 430x430 16 out
        # 524208 for 256x256 16 out
        # 163815 for 256x256 5 out
        # 32763 for 256x256 1 out | kernel 10 
    def forward(self, x):
        x = self.conv1(x)
        # flatten the output of conv1
        x = x.view(x.size(0), -1)       
        return self.out(x)

class LeNet5(nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 6, 5),  
            nn.ReLU(),
            nn.MaxPool2d(2, 2), 
            nn.Conv2d(6, 16, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 120, 5),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(120*28*28, 120),  
            nn.ReLU(),
            nn.Linear(120, 84),
            nn.ReLU(),
            nn.Linear(84, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.conv_layers(x)
        #print(x.shape)  # Add this line
        x = x.view(x.size(0), -1)
        x = self.fc_layers(x)
        return x