import torch
import torch.nn as nn  
import torch.optim as optim  
import torchvision.transforms as transforms  
import torchvision
import os
import pandas as pd
from PIL import Image
from torchvision.transforms import Lambda
from torchvision.transforms import Grayscale
from torch.utils.data import (
    Dataset,
    DataLoader,
)  


class MalwareAndBenignDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])
        image = Image.open(img_path)
        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))

        if self.transform:
            image = self.transform(image)

        return (image, y_label)


# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = 2
learning_rate = 3e-4
batch_size = 32
num_epochs = 10
wd = 1e-5

directory = os.path.join(os.getcwd(), "code", "model")
csv = os.path.join(directory, "data", "arm.csv")
print(csv)
training_data = os.path.join(directory, "data", "arm")

dataset = MalwareAndBenignDataset(
    csv_file= csv,
    root_dir= training_data,
    transform=transforms.Compose([
        Grayscale(num_output_channels=3),  # Convert grayscale image to RGB
        transforms.ToTensor(),
    ]),
)

dataset_length = len(dataset)

train_length = int(dataset_length * 0.7)  # Use 70% of the data for training
test_length = dataset_length - train_length  # Use the rest for testing

# Split the dataset
train_set, test_set = torch.utils.data.random_split(dataset, [train_length, test_length])
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)

# Model
model = torchvision.models.googlenet(weights="DEFAULT")

# freeze all layers, change final linear layer with num_classes
'''
for param in model.parameters():
    param.requires_grad = False
'''

# Modify model final layer to sigmoid
model.fc = nn.Sequential(
    nn.Linear(model.fc.in_features, num_classes),
    nn.Sigmoid()
)

model.to(device)

# Loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=wd)

# Train Network
for epoch in range(num_epochs):
    losses = []

    for batch_idx, (data, targets) in enumerate(train_loader):
        # Get data to cuda if possible
        #data = data.to(device=device)
        data = data.repeat(1, 3, 1, 1)
        targets = targets.to(device=device)

        # forward
        scores = model(data)
        loss = criterion(scores, targets)

        losses.append(loss.item())

        # backward
        optimizer.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer.step()

    print(f"Cost at epoch {epoch} is {sum(losses)/len(losses)}")

# Check accuracy on training to see how good our model is
def check_accuracy(loader, model):
    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)

            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

        print(
            f"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}"
        )

    model.train()


print("Checking accuracy on Training Set")
check_accuracy(train_loader, model)

print("Checking accuracy on Test Set")
check_accuracy(test_loader, model)

model_directory = os.path.join(directory, "model.pth")

torch.save(model.state_dict(), model_directory)
