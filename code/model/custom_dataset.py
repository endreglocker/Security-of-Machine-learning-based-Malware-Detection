import torch
import os
import numpy as np
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms  
from torch.utils.data import DataLoader

class MalwareAndBenignDataset(Dataset):
    def __init__(self, csv_file, root_dir):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        
    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        bin_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])
        with open(bin_path, 'rb') as f:
            binary_data = f.read()
        binary_data = [int(b) for b in binary_data]  # Convert bytes to integers
        reshaped_data = self.reshape_data(binary_data)  # Convert list to tensor
        binary_data_to_tensor = torch.tensor(reshaped_data).unsqueeze(0)  # Convert list to tensor # maybe remove unsqueeze
        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))

        binary_data_to_tensor = binary_data_to_tensor.float()
        return (binary_data_to_tensor, y_label)
    
    def reshape_data(self, binary_data):
        shrunk_array = []
        target_length = 256*256 # 184900 is 430 * 430 px
        if len(binary_data) < target_length:
            binary_data += [0] * (target_length - len(binary_data))
            shrunk_array = binary_data
        elif len(binary_data) > target_length:
            factor = len(binary_data) / target_length

            for i in range(target_length):
                start_index = int(i * factor)
                end_index = int((i + 1) * factor)
                # Calculate the average for this segment
                segment_average = int(np.mean(binary_data[start_index:end_index]).round())
                shrunk_array.append(segment_average)
        else:
            shrunk_array = binary_data
        return shrunk_array
        
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = 2
learning_rate = 3e-4
batch_size = 32
num_epochs = 10
weight_decay = 1e-5

directory = os.path.join(os.getcwd(), "code", "model")
csv = os.path.join(directory, "data", "training.csv")
training_data = os.path.join(directory, "data", "training")


dataset = MalwareAndBenignDataset(
    csv_file= csv,
    root_dir= training_data,
    #transform=transforms.ToTensor(),
)

dataset_length = len(dataset)

# Split the dataset
train_length = int(dataset_length * 0.7 * 0.1)  # Use 70% of the data for training
test_length = int((dataset_length - train_length) * 0.95)  # Use 10% for testing = 100% - 70% = 30% / 3 = 10%
validation_length = dataset_length - train_length - test_length  # Use the rest for validation

train_set, test_set, validation_set = torch.utils.data.random_split(dataset, [train_length, test_length, validation_length])
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)
validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True)


