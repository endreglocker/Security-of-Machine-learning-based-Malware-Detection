import numpy as np
import torch
import os
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms  
from torch.utils.data import DataLoader

class MalwareAndBenignDataset(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])
        image = Image.open(img_path)
        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))

        if self.transform:
            image = self.transform(image)

        # Reshape the image to fit the 1D convolution
        image = image.view(image.size(0), -1)
        
        return (image, y_label)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

num_classes = 2
learning_rate = 3e-4
batch_size = 32
num_epochs = 10
weight_decay = 1e-5

directory = os.path.join(os.getcwd(), "code", "model")
csv = os.path.join(directory, "data", "training.csv")
training_data = os.path.join(directory, "data", "training")


dataset = MalwareAndBenignDataset(
    csv_file= csv,
    root_dir= training_data,
    transform=transforms.ToTensor(),
)

dataset_length = len(dataset)

# Split the dataset
train_length = int(dataset_length * 0.7)  # Use 70% of the data for training
test_length = int((dataset_length - train_length) / 3.0)  # Use 20% for testing
validation_length = dataset_length - train_length - test_length  # Use the rest for validation

train_set, test_set, validation_set = torch.utils.data.random_split(dataset, [train_length, test_length, validation_length])
train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)
validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=True)


# In case we want to parse files as binary data
"""
class MalwareAndBenignDataset(Dataset):
    def __init__(self, csv_file, root_dir):
        self.annotations = pd.read_csv(csv_file)
        self.root_dir = root_dir
        
    def __len__(self):
        return len(self.annotations)

    def __getitem__(self, index):
        bin_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])
        with open(bin_path, 'rb') as f:
            binary_data = f.read()
        binary_data = [int(b) for b in binary_data]  # Convert bytes to integers
        binary_data = self.reshape_data(binary_data)  # Convert list to tensor
        binary_data = torch.tensor(binary_data)  # Convert list to tensor
        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))

        return (binary_data, y_label)
    
    def reshape_data(binary_data):
        target_length = 184427
        if len(binary_data) < target_length:
            binary_data += [0] * (target_length - len(binary_data))

        factor = len(binary_data) / target_length
    
        shrunk_array = []
        for i in range(target_length):
            start_index = int(i * factor)
            end_index = int((i + 1) * factor)
            # Calculate the average for this segment
            segment_average = np.mean(binary_data[start_index:end_index])
            shrunk_array.append(segment_average)

        binary_data = shrunk_array
        return binary_data
"""