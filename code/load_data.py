import os
import torch
import numpy as np

def load_file_names():
    malware_root_path = os.path.join(os.getcwd(), "code", "dataset","malware")
    benign_root_path = os.path.join(os.getcwd(), "code", "dataset","benign")
    m_arm = os.path.join(malware_root_path, "arm")
    m_mips = os.path.join(malware_root_path, "mips")
    b_arm = os.path.join(benign_root_path, "arm")
    b_mips = os.path.join(benign_root_path, "mips")

    malwares = []
    for filename in os.listdir(m_arm):
        image_path = os.path.join(m_arm, filename)
        data = (image_path,1)
        malwares.append(data)

    for filename in os.listdir(m_mips):
        image_path = os.path.join(m_mips, filename)
        data = (image_path,1)
        malwares.append(data)

    benigns = []
    for filename in os.listdir(b_arm):
        image_path = os.path.join(b_arm, filename)
        data = (image_path,0)
        benigns.append(data)

    for filename in os.listdir(b_mips):
        image_path = os.path.join(b_mips, filename)
        data = (image_path,0)
        benigns.append(data)

    return malwares, benigns

def file_to_array(path, target_length=256*256, percentage=0.0):
    with open(path[0], 'rb') as f:
        binary_data = f.read()

    binary_data = [int(b) for b in binary_data]  # Convert bytes to integers
    original_length = len(binary_data)
    # Resize the data to the target length
    binary_data, bigger_or_equal = resize_array(binary_data, target_length, percentage)

    binary_data = [x / 255.0 for x in binary_data]
    # Convert the list to a tensor
    tensor_data = torch.tensor(binary_data, dtype=torch.float32)

    # Reshape the tensor to the expected input shape
    tensor_data = tensor_data.view(1, -1).float()

    ground_truth = torch.tensor([path[1]]).view(1,1).float()

    return tensor_data, ground_truth, original_length, bigger_or_equal

def resize_array(binary_data, target_length, percentage=0.0):
    file_length = len(binary_data)
    file_buffer_length = 1.0 + percentage 
    modified_target_length = int(file_length * file_buffer_length)
 
    # Question:
    # Should I increase the size of a file to midified_target_length even if it exceeds the target_length?
    # Because if i padd it, then it will be shrinked later, which destroys the data
    # and len(binary_data) >= target_length ?
    if percentage > 0.0:
        if modified_target_length <= target_length:
            isBiggerOrEqual = False
        else:
            binary_data = padding(binary_data, modified_target_length)
            isBiggerOrEqual = True
    
    modified_data = []
    #print(f"binary_data:\t{len(binary_data)}")

    if modified_target_length > target_length:
        modified_data = shrink(binary_data, target_length)
    elif modified_target_length < target_length:
        modified_data =  padding(binary_data, target_length)
    elif modified_target_length == target_length:
        modified_data =  binary_data


    #print(f"Target_length:\t{target_length}\nModified target:\t{modified_target_length}\nModified data:\t{len(modified_data)}")
    return modified_data, isBiggerOrEqual

def padding(binary_data, target_length):
    return binary_data + [0] * (target_length - len(binary_data))

def shrink(binary_data, target_length):
    factor = len(binary_data) / target_length
    shrunk_array = []
    for i in range(target_length):
        start_index = int(i * factor)
        end_index = int((i + 1) * factor)
        # Calculate the average for this segment
        segment_average = int(np.mean(binary_data[start_index:end_index]).round())
        shrunk_array.append(segment_average)
    return shrunk_array


def revert_tensor_to_bytes(tensor_data, filename, original_length):
    tensor_data = tensor_data.view(-1)
    tensor_data = tensor_data * 255.0
    tensor_data = tensor_data.round().int()

    #print(tensor_data.numel())

    if(tensor_data.numel() > original_length):
        reshaped_data = tensor_data[:original_length]
    elif(tensor_data.numel() < original_length):
        reshaped_data = torch.cat((tensor_data, torch.zeros(original_length - tensor_data.numel(), dtype=torch.int32)))
    else:
        reshaped_data = tensor_data

    #print(reshaped_data)
    #print(reshaped_data.numel())
    byte_array = bytearray(reshaped_data)

    file_name = os.path.basename(filename)

    path = os.path.join(os.getcwd(), "code", "saved", file_name)
    with open(path, 'wb') as f:
        f.write(byte_array)