import os
import torch
import attack_implementations as aim
import torch.nn as nn
import sys
sys.path.append(os.path.join(os.getcwd(), "code", "model"))
from custom_models import Net

sys.path.append(os.path.join(os.getcwd(), "code"))
import load_data as ld

directory = os.path.join(os.getcwd(), "code", "model",'model256_v2.pth')

loading = torch.load(directory, map_location=torch.device('cpu'))

model = Net()

model.load_state_dict(loading)
model.eval()


malwares, benigns = ld.load_data()
data_array, ground_truth = ld.file_to_array(malwares[100])
data_array = data_array.unsqueeze(0)

data_array = data_array.to(next(model.parameters()).device)
data_array.requires_grad = True


epsilon = 0.5
alpha = 1e-2
num_iter = 40
restarts = 20
loss_fn = nn.BCEWithLogitsLoss()
percentage = 0.6

delta = aim.pgd_linf_rand(model, data_array, ground_truth, epsilon, alpha, num_iter, restarts, loss_fn, percentage)

data_prediction = model(data_array)
data_prediction.backward()

perturbated_image = data_array + delta
perturbated_image.clamp_(0, 1)
perturbated_image = perturbated_image.round_()

aim.save_tensors("test2",delta, data_array, perturbated_image)

perturbated_image_leaf = perturbated_image.detach().clone()
perturbated_image_leaf.requires_grad = True

perturbated_pred = model(perturbated_image_leaf)
perturbated_pred.backward()

dict = {0: "benign", 1: "malware"}
#print(data_prediction.max(dim=1)[0].item())
sol_o = torch.sigmoid(data_prediction).round().int().item()
sol_p = torch.sigmoid(perturbated_pred).round().int().item()

#print(f"Original:\t{torch.sigmoid(data_prediction).item()}")
#print(f"Perturbated:\t{torch.sigmoid(perturbated_pred).item()}")
print(f"Original:\t{dict[sol_o]}")
print(f"Perturbated:\t{dict[sol_p]}")

aim.plot_images(data_array, perturbated_image_leaf, delta, dict, dict[sol_o], dict[sol_p])


# vissza byte arrajbe

# suffex / teljes fájl arány legyen két három teszt pl. max 10% + vissza mappelés
# ellenőrzés, hogy a kép megfelelő-e

# robosztusság

# megtámadott mintán frissíteni a modellt
# megnézni, hogy mennyire javult a modell, ha tanító mintán frissítjük

# black box -> vagy transfer learning / approximálni a gradienst
# határértékes differenciálás def alapján

# poisoning - tanító minta manipulálása
# poising ellentétes grádienssel beszúrni -> semlegesíti / felerősíte egyes feature-öket

# gradient alignment