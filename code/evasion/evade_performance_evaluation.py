import os
import torch
import attack_implementations as aim
import torch.nn as nn
import sys
sys.path.append(os.path.join(os.getcwd(), "code", "model"))
from custom_models import Net

sys.path.append(os.path.join(os.getcwd(), "code"))
import load_data as ld

# Load the model & set it to evaluation mode
directory = os.path.join(os.getcwd(), "code", "model",'model256_v2.pth')

loading = torch.load(directory, map_location=torch.device('cpu'))

model = Net()

model.load_state_dict(loading)
model.eval()

# Load the datasets
file_percentage = 0.095
malwares, benigns = ld.load_file_names()

def performance(dataset, file_percentage=0.1):
    correct = 0
    total = len(dataset)
    for d in dataset:
        data_array, ground_truth, original_length, bigger_or_equal = ld.file_to_array(d, percentage=file_percentage)
        data_array = data_array.unsqueeze(0)

        data_array = data_array.to(next(model.parameters()).device)

        # Set the hyperparameters for the attack
        epsilon = 0.5
        alpha = 1e-2
        num_iter = 40
        restarts = 20
        loss_fn = nn.BCEWithLogitsLoss()

        # Calculate the percentage scaling factor if the file is compressed
        model_input_data_length = 256*256
        modified_percentage = file_percentage * model_input_data_length / (original_length * (1 + file_percentage)) 

        percentage = modified_percentage if bigger_or_equal else file_percentage
        #print(f"Original Percentage: {file_percentage}\tCompressed Percentage: {percentage}")

        delta = aim.pgd_linf_rand(model, data_array, ground_truth, epsilon, alpha, num_iter, restarts, loss_fn, percentage)
        perturbated_image = data_array + delta
        perturbated_image.clamp_(0, 1)

        perturbated_image_leaf = perturbated_image.detach().clone()

        perturbated_pred = model(perturbated_image_leaf)

        ground_truth_value = ground_truth.item()
        prediction_value = torch.sigmoid(perturbated_pred).round().item()
        #print(f"Ground Truth: {ground_truth_value}\nPrediction: {prediction_value}")

        if ground_truth_value == prediction_value:
            correct += 1
        

    return correct / total


print(f"Malware evasion accuracy at 5% modification:\t\t{performance(malwares, 0.05)}")
#print(f"Benign evasion accuracy at 5% modification:\t\t{performance(benigns, 0.05)}")

print(f"Malware evasion accuracy at 10% modification:\t\t{performance(malwares, 0.1)}")
#print(f"Benign evasion accuracy at 10% modification:\t\t{performance(benigns, 0.1)}")

print(f"Malware evasion accuracy at 15% modification:\t\t{performance(malwares, 0.15)}")
#print(f"Benign evasion accuracy at 15% modification:\t\t{performance(benigns, 0.15)}")

print(f"Malware evasion accuracy at 20% modification:\t\t{performance(malwares, 0.2)}")
#print(f"Benign evasion accuracy at 20% modification:\t\t{performance(benigns, 0.2)}")